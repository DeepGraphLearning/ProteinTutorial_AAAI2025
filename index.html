<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Artificial Intelligence for Protein Design, AAAI 2025 Tutorial</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" type="image/png" href="/images/favicon-32x32.svg">
  <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/css/style.css" rel="stylesheet">
  
  <meta property="og:title" content="" />
  <meta property="og:type" content="" />
  <meta property="og:url" content="" />
  <meta property="og:image" content="" />
  <meta property="og:description" content="" />
</head>
<body class='page '>
  <div id="main-menu-mobile" class="main-menu-mobile">
  <ul>
    
  </ul>
</div>

  <div id="wrapper" class="wrapper">
    
    <div class="container pb-6 pt-6 pt-md-10 pb-md-10">
  <div class="row justify-content-start">
    <div class="col-12 col-md-12">
      <h1 class="title">AAAI 2025 Tutorial<br>Artificial Intelligence for Protein Design</h1>
      
<div class="row">

  <div class="col-12 col-md-4 mb-2">
    <div class="team team-summary team-summary-large">
      
      <div class="team-image">
        <img alt="Zuobai Zhang" class="img-fluid mb-2" src="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/images/team/zuobai_zhang.JPG" />
      </div>
      
      <div class="team-meta">
        <h2 class="team-name"><a href="https://https://oxer11.github.io//">Zuobai Zhang</a></h2>
        <p class="team-description">Mila - Quebec AI Institute</p>
      </div>
    </div>
  </div>

  <div class="col-12 col-md-4 mb-2">
    <div class="team team-summary team-summary-large">
      
      <div class="team-image">
        <img alt="Jiarui Lu" class="img-fluid mb-2" src="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/images/team/jiarui_lu.JPG" />
      </div>
      
      <div class="team-meta">
        <h2 class="team-name"><a href="https://lujiarui.github.io/">Jiarui Lu</a></h2>
        <p class="team-description">Mila - Quebec AI Institute</p>
      </div>
    </div>
  </div>

  <div class="col-12 col-md-4 mb-2">
    <div class="team team-summary team-summary-large">
      
      <div class="team-image">
        <img alt="Divya Nori" class="img-fluid mb-2" src="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/images/team/divya_nori.png" />
      </div>
      
      <div class="team-meta">
        <h2 class="team-name"><a href="https://divnori.github.io/">Divya Nori</a></h2>
        <p class="team-description">MIT</p>
      </div>
    </div>
  </div>

  <div class="col-12 col-md-4 mb-2">
    <div class="team team-summary team-summary-large">
      
      <div class="team-image">
        <img alt="Jiwoong Park" class="img-fluid mb-2" src="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/images/team/jiwoong_park.jpg" />
      </div>
      
      <div class="team-meta">
        <h2 class="team-name"><a href="https://jiwoongpark92.github.io/">Jiwoong Park</a></h2>
        <p class="team-description">Northeastern University</p>
      </div>
    </div>
  </div>

  <div class="col-12 col-md-4 mb-2">
    <div class="team team-summary team-summary-large">
      
      <div class="team-image">
        <img alt="Wengong Jin" class="img-fluid mb-2" src="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/images/team/wengong_jin.png" />
      </div>
      
      <div class="team-meta">
        <h2 class="team-name"><a href="https://wengong-jin.github.io/">Wengong Jin</a></h2>
        <p class="team-description">Northeastern University</p>
      </div>
    </div>
  </div>
  
  <div class="col-12 col-md-4 mb-2">
    <div class="team team-summary team-summary-large">
      
      <div class="team-image">
        <img alt="Jian Tang" class="img-fluid mb-2" src="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/images/team/jian_tang.jpg" />
      </div>
      
      <div class="team-meta">
        <h2 class="team-name"><a href="https://jian-tang.com/">Jian Tang</a></h2>
        <p class="team-description">Mila - Quebec AI Institute</p>
      </div>
    </div>
  </div>
  
</div>

<h2 id="abstract">Abstract</h2>
<p>Proteins are fundamental to biological processes, and AI techniques are revolutionizing their study, with applications ranging from drug 
  discovery to enzyme design. A key challenge in protein science is to predict and design protein sequences and structures, and to model 
  their dynamics. In this tutorial, we will present a comprehensive overview of AI approaches applied to protein sequence, structure, and 
  function prediction and design. Topics include sequence-based and structure-based protein representation learning, protein folding and 
  dynamics prediction, and protein design with generative models. Participants are expected to have a foundational understanding of machine 
  learning methods (e.g., neural networks, generative models). No prior experience with computational biology or bioinformatics is necessary, 
  as the tutorial will include a comprehensive introduction to the field.</p>

<h2 id="schedule">Schedule</h2>
<p>8:30 am - 12:30 pm EST, February 26, 2025</p>

<h2 id="schedule">Location</h2>
<p>Room 117, Philadelphia Convention Center, Philadelphia, PA USA</p>

<h2 id="slides">Slides</h2>
<p>The slides can be found <a href="TBA">here</a>.</p>

<h2 id="outline">Outline</h2>

<ul>
  <li><strong>Part I: Introduction [30 min, Wengong]</strong>
    <ul>
      <li>Protein 101: Understanding and Modeling</li>
      <li>Learning on Protein Data</li>
      <li>Methodology Overview</li>
      <li><strong>@Wengong: To be updated</strong></li>
    </ul>
  </li>
  <li><strong>Part II: Protein Representation Learning [60 min, Zuobai]</strong>
    <ul>
      <li>Sequence Representation Learning
        <ul>
          <li>TAPE [<a class="citation" href="#rao2019tape">(Rao et al., 2019)</a>]</li>
          <li>ProtTrans [<a class="citation" href="#elnaggar2021prottrans">(Elnaggar et al., 2021)</a>]</li>
          <li>ESM-1 [<a class="citation" href="#rives2021esm">(Rives et al., 2021)</a>], ESM-2 [<a class="citation" href="#lin2023esm2">(Lin et al., 2023)</a>]</li>
        </ul>
      </li>
      <li>Structure Representation Learning
        <ul>
          <li>Geometric Deep Learning [EGNN <a class="citation" href="#satorras2021egnn">(Satorras et al., 2021)</a>]</li>
          <li>Protein Structure Encoder [GVP <a class="citation" href="#jing2021gvp">(Jing et al., 2021)</a>, GearNet <a class="citation" href="#zhang2023gearnet">(Zhang et al., 2023)</a>, CDConv <a class="citation" href="#fan2023cdconv">(Fan et al., 2023)</a>]
            <!-- <ul>
              <li>EGNN [<a class="citation" href="#satorras2021egnn">(Satorras et al., 2021)</a>]</li>
              <li>GVP [<a class="citation" href="#jing2021gvp">(Jing et al., 2021)</a>]</li> 
              <li>GearNet [<a class="citation" href="#zhang2023gearnet">(Zhang et al., 2023)</a>]</li>
              <li>CDConv [<a class="citation" href="#fan2023cdconv">(Fan et al., 2023)</a>]</li>
            </ul> -->
          </li>
          <li>Structure Pre-training Algorithm [GearNet <a class="citation" href="#zhang2023gearnet">(Zhang et al., 2023)</a>, SiamDiff <a class="citation" href="#zhang2023siamdiff">(Zhang et al., 2023)</a>]
            <!-- <ul>
              <li>GearNet [<a class="citation" href="#zhang2023gearnet">(Zhang et al., 2023)</a>]</li>
              <li>SiamDiff [<a class="citation" href="#zhang2023siamdiff">(Zhang et al., 2023)</a>]</li>
            </ul> -->
          </li>
        </ul>
      </li>
      <li>Multi-Modality Representation Learning
        <ul>
          <li>Sequence + Structure [ESM-GearNet <a class="citation" href="#zhang2023esmgearnet">(Zhang et al., 2023)</a>, SaProt <a class="citation" href="#su2023saprot">(Su et al., 2023)</a>, DPLM-2 <a class="citation" href="#wang2024dplm2">(Wang et al., 2024)</a>]</li>
          <li>Sequence + Text [ProtST <a class="citation" href="#xu2023protst">(Xu et al., 2023)</a>]</li>
          <li>Sequence + Structure + Function [ESM3 <a class="citation" href="#hayes2024esm3">(Hayes et al., 2024)</a>]</li>
        </ul>
      </li>
      <li>Open Source Platform TorchProtein</li>
    </ul>
  </li>
  <li><strong>Break: 15 min</strong></li>
  <li><strong>Part III: Protein Structure and Dynamics Prediction [60 min, Jiarui]</strong>
    <ul>
      <li>Protein Folding and Side-Chain Packing
        <ul>
          <li>AlphaFold 2, RosettaFold [], ESMFold []</li>
          <li>DiffPack []</li>
        </ul>
      </li>
      <li>Protein Complex Docking
        <ul>
          <li>DiffDock []</li>
          <li>AlphaFold2-Multimer [], AlphaFold3 []</li>
        </ul>
      </li>
      <li>Protein Conformation Sampling
        <ul>
          <li>Boltzman Generator []</li>
          <li>EigenFold []</li>
          <li>Str2Str []</li>
          <li>AlphaFlow []</li>
          <li>ConfDiff []</li>
        </ul>
      </li>
      <li>Neural Protein MD Simulators
        <ul>
          <li>CGNet []</li>
          <li>ITO []</li>
          <li>TimeWarp []</li>
        </ul>
      </li>
      <li><strong>@Jiarui: To be updated</strong></li>
    </ul>
  </li>
  <li><strong>Part IV: Protein Design [60 min, Wengong]</strong>
    <ul>
      <li>Sequence Design
        <ul>
          <li>ProGen [], ProGen-2 []</li>
          <li>ESM-IF [], ProteinMPNN []</li>
        </ul>
      </li>
      <li>Structure Design
        <ul>
          <li>FrameDiff [], FrameFlow []</li>
          <li>Genie [], Genie2 []</li>
          <li>Chroma []</li>
          <li>RFDiffusion []</li>
          <li>FoldFlow [], FoldFlow-2 []</li>
        </ul>
      </li>
      <li>Sequence-Structure Co-Design
        <ul>
          <li>ProtSeed [], ProteinGenerator [], MultiFlow [], Protpardelle [], DPLM-2 [</li>
        </ul>
      </li>
      <li>Antibody Design [RefineGNN (Jin et al., 2021)]</li>
      <li><strong>@Wengong: To be updated</strong></li>
    </ul>
  </li>
  <li><strong>Part V: Concluding Remarks and Future Works [15 min, Jian]</strong>
    <ul>
      <li>QA [5 min]</li>
    </ul>
  </li>
</ul>


<h2 id="organizers">Organizers</h2>

<ul>
  <li>Zuobai Zhang, <a href="https://https//oxer11.github.io//">website</a><br />
    <ul>
      <li>Zuobai Zhang is a 4th-year Ph.D. student at Mila – Québec AI Institute, advised by Prof. Jian Tang. He obtained B.Sc. in computer science from Fudan University. Previously, he interned at the Fundamental GenAI team at NVResearch. His research focuses on developing protein structure foundation models.</li>
      <!-- <li><strong>Relevant reviewing experience.</strong>  Jian Tang has served as a reviewer at the major conferences of machine learning, data mining, and natural language processing communities including NIPS, ICML, ICLR, AAAI, IJCAI, ACL, EMNLP, KDD, WWW, and WSDM.</li> -->
    </ul>
  </li>
  <li>Jiarui Lu, <a href="https://jian-tang.com/">website</a><br />
    <ul>
      <li>Jiarui Lu is a 3rd-year Ph.D. student at Mila - Québec AI Institute, supervised by Prof. Jian Tang. He obtained B.Sc. in chemistry and mathematics from Shanghai Jiao Tong University. His research focuses on generative learning on biomolecular structure data such as proteins.  
      </li>
      </ul>
  </li>
  <li>Divya Nori, <a href="https://divnori.github.io/">website</a><br />
    <ul>
      <li>Divya Nori is a Senior and joint Master’s student at MIT  and student researcher at the Broad Institute, advised by Prof. Wengong Jin and Prof. Caroline Uhler. Previously, she interned on the ML teams at D.E. Shaw Research, Absci, and Microsoft Research. Her research focuses on developing AI methods for biomolecular design.
      </li>
      </ul>
  </li>
  <li>Jiwoong Park, <a href="https://jiwoongpark92.github.io/">website</a><br />
    <ul>
      <li>Jiwoong Park is a postdoctoral researcher at Northeastern University working with Professor Wengong Jin. He completed his PhD in electrical and computer engineering at Seoul National University. His research field is generative models for drug design and machine learning for graph-structured data.
      </li>    
    </ul>
  </li>
  <li>Wengong Jin, <a href="https://wengong-jin.github.io/">website</a><br />
    <ul>
      <li>Wengong Jin is an assistant professor at Khoury College of Computer Sciences at Northeastern University. His research focuses on geometric and generative AI models for drug discovery. His work has been published in journals including ICML, NeurIPS, ICLR, Nature, Science, Cell, and PNAS, and covered by such outlets as the Guardian, BBC News, and CBS Boston.
      </li>
    </ul>
  </li>
  <li>Jian Tang, <a href="https://jian-tang.com/">website</a><br />
    <ul>
      <li>Jian Tang is an associate professor at Mila - Québec AI Institute, a Canada CIFAR AI Research Chair and the founder and CEO of BioGeometry. His research interests are deep generative models, graph machine learning and their applications to drug discovery. He has done many pioneering work on AI for drug discovery, including the first open-source machine learning framework for drug discovery, TorchDrug and TorchProtein.
      </li>
    </ul>
  </li>
</ul>

<h2 id="references">References</h2>
<ol class="bibliography">
<li><span id="rao2019tape">Rao, Roshan, et al. (2019). Evaluating protein transfer learning with TAPE. <i>NeuIPS</i>.</span></li>
<li><span id="elnaggar2021prottrans">Elnaggar, Ahmed, et al. (2021) Prottrans: Toward understanding the language of life through self-supervised learning. <i>TPAMI</i>.</span></li>
<li><span id="rives2021esm">Rives, Alexander, et al. (2021) Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. <i>PNAS</i>.</span></li>
<li><span id="lin2023esm2">Lin, Zeming, et al. (2023) Evolutionary-scale prediction of atomic-level protein structure with a language model. <i>Science</i>.</span></li>
<li><span id="satorras2021egnn">Satorras, Vıctor Garcia, Emiel Hoogeboom, and Max Welling. (2021) E(n) equivariant graph neural networks. <i>ICML</i>.</span></li>
<li><span id="jing2021gvp">Jing, Bowen, et al. (2021) Learning from protein structure with geometric vector perceptrons. <i>ICLR</i>.</span></li>
<li><span id="zhang2023gearnet">Zhang, Zuobai, et al. (2023) Protein representation learning by geometric structure pretraining. <i>ICLR</i>.</span></li>
<li><span id="fan2023cdconv">Fan, Hehe, et al. (2023) Continuous-discrete convolution for geometry-sequence modeling in proteins. <i>ICLR</i>.</span></li>
<li><span id="zhang2023siamdiff">Zhang, Zuobai, et al. (2023) Pre-training protein encoder via siamese sequence-structure diffusion trajectory prediction. <i>NeurIPS</i>.</span></li>
<li><span id="zhang2023esmgearnet">Zhang, Zuobai, et al. (2023) A systematic study of joint representation learning on protein sequences and structures. <i>ArXiv Preprint ArXiv:2303.06275</i>.</span></li>
<li><span id="su2023saprot">Su, Jin, et al. (2024) Saprot: Protein language modeling with structure-aware vocabulary. <i>ICLR</i>.</span></li>
<li><span id="wang2024dplm2">Wang, Xinyou, et al. (2025) DPLM-2: A multimodal diffusion protein language model. <i>ICLR</i>.</span></li>
<li><span id="xu2023protst">Xu, Minghao, et al. (2023) Protst: Multi-modality learning of protein sequences and biomedical texts. <i>ICML</i>.</span></li>
<li><span id="hayes2024esm3">Hayes, Thomas, et al. (2024) Simulating 500 million years of evolution with a language model. <i>Science</i>.</span></li>




<!-- <li><span id="sun2019infograph">Sun, F.-Y., Hoffmann, J., Verma, V., &amp; Tang, J. (2020). Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization. <i>ICLR</i>.</span></li>
<li><span id="xu2021end">Xu, M., Wang, W., Luo, S., Shi, C., Bengio, Y., Gomez-Bombarelli, R., &amp; Tang, J. (2021). An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming. <i>ArXiv Preprint ArXiv:2105.07246</i>.</span></li>
<li><span id="shi2021learning">Shi, C., Luo, S., Xu, M., &amp; Tang, J. (2021). Learning gradient fields for molecular conformation generation. <i>ArXiv Preprint ArXiv:2105.03902</i>.</span></li>
<li><span id="xu2021learning">Xu, M., Luo, S., Bengio, Y., Peng, J., &amp; Tang, J. (2021). Learning neural generative dynamics for molecular conformation generation. <i>ArXiv Preprint ArXiv:2102.10240</i>.</span></li>
<li><span id="shi2020graphaf">Shi, C., Xu, M., Zhu, Z., Zhang, W., Zhang, M., &amp; Tang, J. (2020). GraphAF: a flow-based autoregressive model for molecular graph generation. <i>ICLR</i>.</span></li>
<li><span id="shhi2020a">Shi, C., Xu, M., Guo, H., Zhang, M., &amp; Tang, J. (2020). A Graph to Graphs Framework for Retrosynthesis Prediction. <i>ICML</i>.</span></li>
<li><span id="gottipati2020learning">Gottipati, S. K., Sattarov, B., Niu, S., Pathak, Y., Wei, H., Liu, S., Thomas, K. M. J., Blackburn, S., Coley, C. W., Tang, J., &amp; others. (2020). Learning To Navigate The Synthetically Accessible Chemical Space Using Reinforcement Learning. <i>ICML</i>.</span></li>
<li><span id="jin2018junction">Jin, W., Barzilay, R., &amp; Jaakkola, T. (2018). Junction tree variational autoencoder for molecular graph generation. <i>ICML</i>.</span></li>
<li><span id="you2018graph">You, J., Liu, B., Ying, Z., Pande, V., &amp; Leskovec, J. (2018). Graph convolutional policy network for goal-directed molecular graph generation. <i>Advances in Neural Information Processing Systems</i>, 6410–6421.</span></li>
<li><span id="zang2020moflow">Zang, C., &amp; Wang, F. (2020). MoFlow: An Invertible Flow Model for Generating Molecular Graphs. <i>Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</i>, 617–626.</span></li>
<li><span id="sun2020graph">Sun, M., Zhao, S., Gilvary, C., Elemento, O., Zhou, J., &amp; Wang, F. (2020). Graph convolutional networks for computational drug development and discovery. <i>Briefings in Bioinformatics</i>, <i>21</i>(3), 919–935.</span></li>
<li><span id="hu2019strategies">Hu, W., Liu, B., Gomes, J., Zitnik, M., Liang, P., Pande, V., &amp; Leskovec, J. (2019). Strategies for Pre-training Graph Neural Networks. <i>ArXiv Preprint ArXiv:1905.12265</i>.</span></li>
<li><span id="gilmer2017neural">Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., &amp; Dahl, G. E. (2017). Neural message passing for quantum chemistry. <i>ArXiv Preprint ArXiv:1704.01212</i>.</span></li>
<li><span id="kipf2016semi">Kipf, T. N., &amp; Welling, M. (2016). Semi-supervised classification with graph convolutional networks. <i>ArXiv Preprint ArXiv:1609.02907</i>.</span></li>
<li><span id="xu2018powerful">Xu, K., Hu, W., Leskovec, J., &amp; Jegelka, S. (2018). How powerful are graph neural networks? <i>ArXiv Preprint ArXiv:1810.00826</i>.</span></li>
<li><span id="jin2017predicting">Jin, W., Coley, C., Barzilay, R., &amp; Jaakkola, T. (2017). Predicting organic reaction outcomes with weisfeiler-lehman network. <i>Advances in Neural Information Processing Systems</i>, 2607–2616.</span></li>
<li><span id="schwaller2019molecular">Schwaller, P., Laino, T., Gaudin, T., Bolgar, P., Hunter, C. A., Bekas, C., &amp; Lee, A. A. (2019). Molecular transformer: A model for uncertainty-calibrated chemical reaction prediction. <i>ACS Central Science</i>, <i>5</i>(9), 1572–1583.</span></li>
<li><span id="sacha2020molecule">Sacha, M., Błaż, M., Byrski, P., Włodarczyk-Pruszyński, P., &amp; Jastrzębski, S. (2020). Molecule Edit Graph Attention Network: Modeling Chemical Reactions as Sequences of Graph Edits. <i>ArXiv Preprint ArXiv:2006.15426</i>.</span></li>
<li><span id="dai2019retrosynthesis">Dai, H., Li, C., Coley, C., Dai, B., &amp; Song, L. (2019). Retrosynthesis prediction with conditional graph logic network. <i>Advances in Neural Information Processing Systems</i>, 8872–8882.</span></li>
<li><span id="zhou2020network">Zhou, Y., Hou, Y., Shen, J., Huang, Y., Martin, W., &amp; Cheng, F. (2020). Network-based drug repurposing for novel coronavirus 2019-nCoV/SARS-CoV-2. <i>Cell Discovery</i>, <i>6</i>(1), 1–18.</span></li>
<li><span id="zeng2019deepdr">Zeng, X., Zhu, S., Liu, X., Zhou, Y., Nussinov, R., &amp; Cheng, F. (2019). deepDR: a network-based deep learning approach to in silico drug repositioning. <i>Bioinformatics</i>, <i>35</i>(24), 5191–5198.</span></li>
<li><span id="zhou2020artificial">Zhou, Y., Wang, F., Jian, T., R., N., &amp; Cheng, F. (2020). Artificial Intelligence in Drug Repurposing. <i>The Lancet Digital Health</i>.</span></li>
<li><span id="chen2020idrug">Chen, H., Cheng, F., &amp; Li, J. (2020). iDrug: Integration of drug repositioning and drug-target prediction via cross-network embedding. <i>PLoS Computational Biology</i>, <i>16</i>(7), e1008040.</span></li>
<li><span id="cheng2019network">Cheng, F., Kovács, I. A., &amp; Barabási, A.-L. (2019). Network-based prediction of drug combinations. <i>Nature Communications</i>, <i>10</i>(1), 1–11.</span></li>
<li><span id="cheng2018network">Cheng, F., Desai, R. J., Handy, D. E., Wang, R., Schneeweiss, S., Barabási, A.-L., &amp; Loscalzo, J. (2018). Network-based approach to prediction and population-based validation of in silico drug repurposing. <i>Nature Communications</i>, <i>9</i>(1), 1–12.</span></li>
<li><span id="gysi2020network">Gysi, D. M., Valle, Í. D., Zitnik, M., Ameli, A., Gan, X., Varol, O., Sanchez, H., Baron, R. M., Ghiassian, D., Loscalzo, J., &amp; others. (2020). Network medicine framework for identifying drug repurposing opportunities for covid-19. <i>ArXiv Preprint ArXiv:2004.07229</i>.</span></li>
<li><span id="zhou2020networkb">Zhou, Y., Hou, Y., Shen, J., Kallianpur, A., Zein, J., Culver, D. A., Farha, S., Comhair, S., Fiocchi, C., Gack, M. U., &amp; others. (2020). A Network Medicine Approach to Investigation and Population-based Validation of Disease Manifestations and Drug Repurposing for COVID-19. <i>ChemRxiv</i>.</span></li></ol> -->

    </div>
  </div>
</div>
  </div>
  <div class="footer">
  <div class="container">
    <div class="row">
      <div class="col-12 mt-2 mb-4">
        <div class="footer-inner">
          <h3 class="footer-title">Artificial Intelligence for Protein Design, AAAI 2025 Tutorial</h3>
          <ul>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
  <script type="text/javascript" src="https://deepgraphlearning.github.io/ProteinTutorial_AAAI2025/assets/js/scripts.js""></script>
  
</body>
</html>
